{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**1. PySpark Setup & Initialization**\n",
        "\n",
        "**Exercise 1.1 – Setup Spark:**\n",
        "\n",
        "Initialize SparkSession with:"
      ],
      "metadata": {
        "id": "dRWyw9vb1ima"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c-ODeoIM1HSc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"BotCampus Intermediate Session\") \\\n",
        ".master(\"local[*]\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1.2 – Load starter data:**"
      ],
      "metadata": {
        "id": "-UCEpFPU2Bpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Ananya\", \"Bangalore\", 24),\n",
        "(\"Ravi\", \"Hyderabad\", 28),\n",
        "(\"Kavya\", \"Delhi\", 22),\n",
        "(\"Meena\", \"Chennai\", 25)]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnOHD6BK2Ej6",
        "outputId": "2c05aa3f-e2ae-49de-bbba-b0d1c64e3cd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Ananya|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. RDDs & Transformations**\n",
        "\n",
        "**Exercise 2.1 – Create RDD from feedback:**"
      ],
      "metadata": {
        "id": "q4wBWNKi2ppy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = sc.parallelize([\n",
        "\"Ravi from Bangalore loved the mobile app\",\n",
        "\"Meena from Delhi reported poor response time\",\n",
        "\"Ajay from Pune liked the delivery speed\",\n",
        "\"Ananya from Hyderabad had an issue with UI\",\n",
        "\"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "NH7AhjHi2mHw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "Count total number of words."
      ],
      "metadata": {
        "id": "VUjDUgDw3Vzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = feedback.flatMap(lambda x: x.split(\" \"))\n",
        "word_count = word.count()\n",
        "print(\"The number of words are: \", word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLMDhmCQ3ZAF",
        "outputId": "66199bbe-9cb5-4a29-eb3c-1a7b3719eb5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words are:  35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find top 3 most common words."
      ],
      "metadata": {
        "id": "JWA_1URL4am9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "common_words = word.map(lambda x: x.lower()).countByValue()\n",
        "common_words = dict(Counter(common_words).most_common(3))\n",
        "print(\"The top 3 most common words are: \", common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9IXinOx4d5p",
        "outputId": "81cf7a89-8987-46e6-dad2-1e1982b7d463"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 3 most common words are:  {'from': 5, 'the': 2, 'ravi': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stop words ( from , with , the , etc.)."
      ],
      "metadata": {
        "id": "U-alq-uD5cSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value = {\"from\", \"with\", \"the\", \"had\", \"an\", \"and\"}\n",
        "\n",
        "fil_word = word.filter(lambda x: x.lower() not in value)\n",
        "count = fil_word.count()\n",
        "print(\"The number of words are: \", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKSCEG2Z5fT1",
        "outputId": "2e2b4e60-c7ea-441f-ee76-de0dee17b614"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words are:  25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dictionary of word → count."
      ],
      "metadata": {
        "id": "S8yZueSw6b06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = dict(word.map(lambda x: (x.lower(), 1)).reduceByKey(lambda a, b: a + b).collect())\n",
        "print(\"Word dictionary:\", word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjylGceJ6eO0",
        "outputId": "e8d12b92-b8b5-4992-9e06-0473de55467e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word dictionary: {'from': 5, 'loved': 1, 'app': 1, 'poor': 1, 'response': 1, 'liked': 1, 'speed': 1, 'ananya': 1, 'an': 1, 'issue': 1, 'with': 1, 'rohit': 1, 'mumbai': 1, 'positive': 1, 'feedback': 1, 'ravi': 1, 'bangalore': 1, 'the': 2, 'mobile': 1, 'meena': 1, 'delhi': 1, 'reported': 1, 'time': 1, 'ajay': 1, 'pune': 1, 'delivery': 1, 'hyderabad': 1, 'had': 1, 'ui': 1, 'gave': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. DataFrames – Transformations**\n",
        "\n",
        "**Exercise 3.1 – Create exam_scores DataFrame:**"
      ],
      "metadata": {
        "id": "iagiae366vVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [\n",
        "(\"Ravi\", \"Math\", 88),\n",
        "(\"Ananya\", \"Science\", 92),\n",
        "(\"Kavya\", \"English\", 79),\n",
        "(\"Ravi\", \"English\", 67),\n",
        "(\"Neha\", \"Math\", 94),\n",
        "(\"Meena\", \"Science\", 85)\n",
        "]\n",
        "columns = [\"name\", \"subject\", \"score\"]\n",
        "\n",
        "df_scores = spark.createDataFrame(scores, columns)\n",
        "\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wcQ3h1y66dl",
        "outputId": "39a48284-781e-47d6-ed56-376ddbf1b254"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+\n",
            "|  name|subject|score|\n",
            "+------+-------+-----+\n",
            "|  Ravi|   Math|   88|\n",
            "|Ananya|Science|   92|\n",
            "| Kavya|English|   79|\n",
            "|  Ravi|English|   67|\n",
            "|  Neha|   Math|   94|\n",
            "| Meena|Science|   85|\n",
            "+------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add grade column ( >=90 → A, 80-89 → B, 70-79 → C, else D)."
      ],
      "metadata": {
        "id": "_EINpyMB7KlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "df_scores = df_scores.withColumn(\n",
        "    \"grade\",\n",
        "    when(col(\"score\") >= 90, \"A\")\n",
        "    .when(col(\"score\") >= 80, \"B\")\n",
        "    .when(col(\"score\") >= 70, \"C\")\n",
        "    .otherwise(\"D\")\n",
        ")\n",
        "\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAZ89l1s7N5-",
        "outputId": "3c5c040a-be82-46e9-9090-14499f3540ca"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+\n",
            "|  name|subject|score|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Ravi|   Math|   88|    B|\n",
            "|Ananya|Science|   92|    A|\n",
            "| Kavya|English|   79|    C|\n",
            "|  Ravi|English|   67|    D|\n",
            "|  Neha|   Math|   94|    A|\n",
            "| Meena|Science|   85|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group by subject, find average score."
      ],
      "metadata": {
        "id": "Fb_W4duW8WVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "grouped = df_scores.groupBy(\"subject\").agg(F.avg(\"score\").alias(\"avg_score\"))\n",
        "grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3WWEQ_8ZPm",
        "outputId": "952a86ea-4b88-40b2-ba07-9c690f7a2fe1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "|English|     73.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use when and otherwise to classify subject difficulty ( Math/Science Difficult)."
      ],
      "metadata": {
        "id": "mGfvhOCh85t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = df_scores.withColumn(\n",
        "    \"difficulty\",\n",
        "    when(col(\"subject\").isin(\"Math\", \"Science\"), \"Difficult\").otherwise(\"Easy\")\n",
        ")\n",
        "\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGDi_Rgk8-TO",
        "outputId": "474a320b-57ac-460a-9ecf-e9bdc3690b24"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  Ravi|   Math|   88|    B| Difficult|\n",
            "|Ananya|Science|   92|    A| Difficult|\n",
            "| Kavya|English|   79|    C|      Easy|\n",
            "|  Ravi|English|   67|    D|      Easy|\n",
            "|  Neha|   Math|   94|    A| Difficult|\n",
            "| Meena|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rank students per subject using Window function."
      ],
      "metadata": {
        "id": "oz41P4739i1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "windowSpec = Window.partitionBy(\"subject\").orderBy(col(\"score\").desc())\n",
        "df_scores = df_scores.withColumn(\"rank\", F.rank().over(windowSpec))\n",
        "\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjJhTTau9mco",
        "outputId": "bd6c2813-ae34-44e9-a756-8be1a426b1f3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+\n",
            "|  name|subject|score|grade|difficulty|rank|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "| Kavya|English|   79|    C|      Easy|   1|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|\n",
            "| Meena|Science|   85|    B| Difficult|   2|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply UDF to format names (e.g., make all uppercase)."
      ],
      "metadata": {
        "id": "83UjjXWE93Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "@udf(returnType=StringType())\n",
        "def format_name(name):\n",
        "    return name.upper()\n",
        "\n",
        "df_scores = df_scores.withColumn(\"formatted\", format_name(\"name\"))\n",
        "\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N0HIzf_-NqU",
        "outputId": "9f85f103-bf99-4cb6-da3a-42b514da8e0e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+---------+\n",
            "|  name|subject|score|grade|difficulty|rank|formatted|\n",
            "+------+-------+-----+-----+----------+----+---------+\n",
            "| Kavya|English|   79|    C|      Easy|   1|    KAVYA|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|     RAVI|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|     NEHA|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|     RAVI|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|   ANANYA|\n",
            "| Meena|Science|   85|    B| Difficult|   2|    MEENA|\n",
            "+------+-------+-----+-----+----------+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Ingest CSV & JSON – Save to Parquet**\n",
        "\n",
        "**Dataset 1: CSV file:**\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "Load both datasets into PySpark."
      ],
      "metadata": {
        "id": "_JtHcDJ8-tRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"id,name,department,city,salary\n",
        "1,Amit,IT,Bangalore,78000\n",
        "2,Kavya,HR,Chennai,62000\n",
        "3,Arjun,Finance,Hyderabad,55000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"students.csv\", \"w\") as f:\n",
        "    f.write(data)\n",
        "\n",
        "df_csv = spark.read.csv(\"students.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "6y5fVTCc-2Bn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 2: JSON file employee_nested.json**"
      ],
      "metadata": {
        "id": "ksz8Bs6uBAwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_data = [\n",
        "{\n",
        "\"id\": 101,\n",
        "\"name\": \"Sneha\",\n",
        "\"address\": {\n",
        "\"city\": \"Mumbai\",\n",
        "\"pincode\": 400001\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\"]\n",
        "}\n",
        "]\n",
        "\n",
        "with open(\"employee_nested.json\", \"w\") as f:\n",
        "    f.write(str(json_data))\n",
        "\n",
        "df_json = spark.read.json(\"employee_nested.json\")"
      ],
      "metadata": {
        "id": "qJtVIbEnBASJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print schema and infer nested structure."
      ],
      "metadata": {
        "id": "dVubsFOaByb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTtsx6nhB6tk",
        "outputId": "7036db5a-ee95-44bd-c5ab-52e7dc910d57"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_json.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0EHKNX8B4Vu",
        "outputId": "c7cb3ff7-0952-456c-fdc2-955fabcb26ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten the JSON (use explode , select , alias )."
      ],
      "metadata": {
        "id": "Ae60_aCwCMf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df_flat = df_json.select(\n",
        "    \"id\",\n",
        "    \"name\",\n",
        "    \"address.city\",\n",
        "    \"address.pincode\",\n",
        "    explode(\"skills\").alias(\"skill\")\n",
        ")\n",
        "\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThU_g5rkCTTV",
        "outputId": "68e39777-e309-4f42-e562-9755be33066b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+-------+------+\n",
            "| id| name|  city|pincode| skill|\n",
            "+---+-----+------+-------+------+\n",
            "|101|Sneha|Mumbai| 400001|Python|\n",
            "|101|Sneha|Mumbai| 400001| Spark|\n",
            "+---+-----+------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert both to Parquet and write to /tmp/output ."
      ],
      "metadata": {
        "id": "lmKpALjSCk1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.write.mode(\"overwrite\").parquet(\"/tmp/output/students_parquet\")\n",
        "df_flat.write.mode(\"overwrite\").parquet(\"/tmp/output/employees_parquet\")"
      ],
      "metadata": {
        "id": "jNpRmE1YCneG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Spark SQL – Temp Views & Queries**\n",
        "\n",
        "**Exercise 5.1 Create view from exam scores and run:**"
      ],
      "metadata": {
        "id": "PYx-lrFeC2q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.createOrReplaceTempView(\"exam_scores\")"
      ],
      "metadata": {
        "id": "Hf5M1nPWDFaN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Top scorer per subject"
      ],
      "metadata": {
        "id": "khNWFPzOGYza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT subject, name, score FROM ( SELECT *, RANK() OVER (PARTITION BY subject ORDER BY score DESC) as rnk FROM exam_scores) WHERE rnk = 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGPCILg9GZli",
        "outputId": "e9a81ea4-9908-4c89-8d41-d81a209b714c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----+\n",
            "|subject|  name|score|\n",
            "+-------+------+-----+\n",
            "|English| Kavya|   79|\n",
            "|   Math|  Neha|   94|\n",
            "|Science|Ananya|   92|\n",
            "+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Count of students per grade"
      ],
      "metadata": {
        "id": "GqlbsUvbG5Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT grade, COUNT(*) as student_count FROM exam_scores GROUP BY grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOVIigWTHASU",
        "outputId": "b27f1756-894a-41e4-993f-79096be19c83"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------+\n",
            "|grade|student_count|\n",
            "+-----+-------------+\n",
            "|    B|            2|\n",
            "|    C|            1|\n",
            "|    A|            2|\n",
            "|    D|            1|\n",
            "+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Students with multiple subjects"
      ],
      "metadata": {
        "id": "UYF8f2mWHpxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT name, COUNT(*) as subjects FROM exam_scores GROUP BY name HAVING subjects > 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo6-J18ZHtAf",
        "outputId": "c5ab75f4-2ddc-4b79-c036-876bbdf4a59d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "|name|subjects|\n",
            "+----+--------+\n",
            "|Ravi|       2|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Subjects with average score above 85"
      ],
      "metadata": {
        "id": "9qBCI9v0H8X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT subject, AVG(score) as avg_score FROM exam_scores GROUP BY subject HAVING avg_score > 85\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZpkHISYH_hp",
        "outputId": "76d25dea-47ce-4b70-c8dd-2a663a43e5a2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5.2 Create another DataFrame attendance(name, days_present) and Join with scores"
      ],
      "metadata": {
        "id": "5vQrUVDsINju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attendance = [(\"Ravi\", 22), (\"Ananya\", 18), (\"Kavya\", 25), (\"Neha\", 21), (\"Meena\", 15)]\n",
        "df_attendance = spark.createDataFrame(attendance, [\"name\", \"days_present\"])\n",
        "\n",
        "df_joined = df_scores.join(df_attendance, on=\"name\", how=\"left\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACfrhti4IUe1",
        "outputId": "083eb590-49c0-4c99-d70d-6a3693e79b9f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+---------+------------+\n",
            "|  name|subject|score|grade|difficulty|rank|formatted|days_present|\n",
            "+------+-------+-----+-----+----------+----+---------+------------+\n",
            "|Ananya|Science|   92|    A| Difficult|   1|   ANANYA|          18|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|     RAVI|          22|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|     RAVI|          22|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|     NEHA|          21|\n",
            "| Meena|Science|   85|    B| Difficult|   2|    MEENA|          15|\n",
            "| Kavya|English|   79|    C|      Easy|   1|    KAVYA|          25|\n",
            "+------+-------+-----+-----+----------+----+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate attendance-adjusted grade:\n",
        "If days_present < 20 → downgrade grade by one level"
      ],
      "metadata": {
        "id": "0pCc-YOUJUQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_adjusted = df_joined.withColumn(\n",
        "    \"final_grade\",\n",
        "    when(col(\"days_present\") < 20,\n",
        "         when(col(\"grade\") == \"A\", \"B\")\n",
        "        .when(col(\"grade\") == \"B\", \"C\")\n",
        "        .when(col(\"grade\") == \"C\", \"D\")\n",
        "        .otherwise(\"D\")\n",
        "    ).otherwise(col(\"grade\"))\n",
        ")\n",
        "\n",
        "df_adjusted.select(\"name\", \"subject\", \"score\", \"grade\", \"days_present\", \"final_grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i7vcZyYJaIG",
        "outputId": "c1f9660e-3607-4855-b8dc-699d6fee3aab"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+------------+-----------+\n",
            "|  name|subject|score|grade|days_present|final_grade|\n",
            "+------+-------+-----+-----+------------+-----------+\n",
            "|Ananya|Science|   92|    A|          18|          B|\n",
            "|  Ravi|   Math|   88|    B|          22|          B|\n",
            "| Kavya|English|   79|    C|          25|          C|\n",
            "|  Ravi|English|   67|    D|          22|          D|\n",
            "|  Neha|   Math|   94|    A|          21|          A|\n",
            "| Meena|Science|   85|    B|          15|          C|\n",
            "+------+-------+-----+-----+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Partitioned Load (Full + Incremental)**\n",
        "\n",
        "**Initial Load:**"
      ],
      "metadata": {
        "id": "5aD5wsFiJqz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.write.partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "swoveDPmJzPq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Incremental Load:**"
      ],
      "metadata": {
        "id": "hpxTpil4LESd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Meena\", \"Math\", 93)]\n",
        "df_inc = spark.createDataFrame(incremental, columns)\n",
        "df_inc.write.mode(\"append\").partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "ae8yfDYWLB75"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:**\n",
        "\n",
        "List all folders inside /tmp/scores/"
      ],
      "metadata": {
        "id": "ABSIOGt_LMO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Partitions:\", os.listdir(\"/tmp/scores/\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTeeWMsxLRaO",
        "outputId": "e6031cdf-8280-46e0-bc89-71a45bba1d1c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partitions: ['._SUCCESS.crc', 'subject=Science', 'subject=English', '_SUCCESS', 'subject=Math']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read only Math partition and display all entries."
      ],
      "metadata": {
        "id": "TPjHxIANLXQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_math = spark.read.parquet(\"/tmp/scores/subject=Math\")\n",
        "df_math.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG239FWHLaRp",
        "outputId": "0f2a598e-ec45-45c9-f408-93475bfcf5b1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----------+----+---------+\n",
            "| name|score|grade|difficulty|rank|formatted|\n",
            "+-----+-----+-----+----------+----+---------+\n",
            "| Neha|   94|    A| Difficult|   1|     NEHA|\n",
            "| Ravi|   88|    B| Difficult|   2|     RAVI|\n",
            "|Meena|   93| NULL|      NULL|NULL|     NULL|\n",
            "+-----+-----+-----+----------+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. ETL: Clean, Transform, Load**\n",
        "\n",
        "**Raw CSV:**"
      ],
      "metadata": {
        "id": "HAWpCa8sLhct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data = \"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,78000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,55000,3000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"raw_employee.csv\", \"w\") as f:\n",
        "    f.write(csv_data)"
      ],
      "metadata": {
        "id": "DVsnndtvLnHW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data with header."
      ],
      "metadata": {
        "id": "-5ynsb5wMBWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = spark.read.csv(\"raw_employee.csv\", header=True, inferSchema=True)\n",
        "df_raw.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paheD5oLMERx",
        "outputId": "620e56eb-e166-4342-ee1d-97f02f6bec82"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| NULL|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill missing bonus with 2000."
      ],
      "metadata": {
        "id": "s3rcD4KvMIoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled = df_raw.fillna({\"bonus\": 2000})\n",
        "df_filled.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSVwwrLWMLtZ",
        "outputId": "1404d525-66c3-4ed4-b6c5-4b112ea61d91"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| 2000|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate total_ctc = salary + bonus ."
      ],
      "metadata": {
        "id": "ZrIAMvZgMTek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ctc = df_filled.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))\n",
        "df_ctc.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EjUgpAAMXLO",
        "outputId": "9211b598-6063-465d-dc14-20af2d4d7d11"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 78000| 5000|    83000|\n",
            "|     2|Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3|Sneha|Finance| 55000| 3000|    58000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter where total_ctc > 60,000."
      ],
      "metadata": {
        "id": "ckqgMaO9Md6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_ctc.filter(col(\"total_ctc\") > 60000)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_xIYb4jMgVi",
        "outputId": "8be29606-4cdc-4fb6-96fe-d498c249a272"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----+------+-----+---------+\n",
            "|emp_id| name|dept|salary|bonus|total_ctc|\n",
            "+------+-----+----+------+-----+---------+\n",
            "|     1|Arjun|  IT| 78000| 5000|    83000|\n",
            "|     2|Kavya|  HR| 62000| 2000|    64000|\n",
            "+------+-----+----+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save final DataFrame to Parquet and JSON."
      ],
      "metadata": {
        "id": "qBsHjqY9Mn3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.write.mode(\"overwrite\").parquet(\"/tmp/final_ctc_parquet\")\n",
        "df_filtered.write.mode(\"overwrite\").json(\"/tmp/final_ctc_json\")"
      ],
      "metadata": {
        "id": "QDNXXBxqMqUJ"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}