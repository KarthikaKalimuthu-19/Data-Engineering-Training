{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 1: Setup & SparkSession Initialization**\n",
        "**Tasks:**\n",
        "\n",
        "Initialize Spark with:"
      ],
      "metadata": {
        "id": "xHftmhz6ShEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-iaZDAStOl82"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"BotCampus PySpark Practice\") \\\n",
        ".master(\"local[*]\") \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame from:"
      ],
      "metadata": {
        "id": "m8KhCYCsa1NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "(\"Anjali\", \"Bangalore\", 24),\n",
        "(\"Ravi\", \"Hyderabad\", 28),\n",
        "(\"Kavya\", \"Delhi\", 22),\n",
        "(\"Meena\", \"Chennai\", 25),\n",
        "(\"Arjun\", \"Mumbai\", 30)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp33Xs3Pa2Gc",
        "outputId": "54491753-a65c-4689-f19a-94a06628446e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Anjali|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "| Arjun|   Mumbai| 30|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show schema, explain data types."
      ],
      "metadata": {
        "id": "Vf4MBvXWbKp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcFHLyGpbKPB",
        "outputId": "6f16c658-d10d-44e3-dc52-28b0f433cd2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPIVU7gkbWP5",
        "outputId": "fbe26447-5bfa-48d2-bb28-27bbc3a0a095"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('name', 'string'), ('city', 'string'), ('age', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to RDD and Print .collect() and df.rdd.map() output."
      ],
      "metadata": {
        "id": "LbVyd5jWbi9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = df.rdd\n",
        "print(rdd.collect())\n",
        "print(rdd.map(lambda x: (x.name.upper(), x.age + 1)).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhh2qoWwcO9Y",
        "outputId": "201d1304-1561-4afa-c357-af30fc25b570"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n",
            "[('ANJALI', 25), ('RAVI', 29), ('KAVYA', 23), ('MEENA', 26), ('ARJUN', 31)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 2: RDDs & Transformations**\n",
        "\n",
        "**Scenario: You received app feedback from users in free-text.**"
      ],
      "metadata": {
        "id": "9R6ro8l2cv3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "feedback = sc.parallelize([\n",
        "\"Ravi from Bangalore loved the delivery\",\n",
        "\"Meena from Hyderabad had a late order\",\n",
        "\"Ajay from Pune liked the service\",\n",
        "\"Anjali from Delhi faced UI issues\",\n",
        "\"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "MPTnEgp5c2yL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "Split each line into words ( flatMap )."
      ],
      "metadata": {
        "id": "nqHwpM8adHWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = feedback.flatMap(lambda x: x.split(\" \"))\n",
        "print(word.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs9Wc4ifdLHl",
        "outputId": "3697cd6b-3d6a-4536-b1c7-e45a886d7a0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ravi', 'from', 'Bangalore', 'loved', 'the', 'delivery', 'Meena', 'from', 'Hyderabad', 'had', 'a', 'late', 'order', 'Ajay', 'from', 'Pune', 'liked', 'the', 'service', 'Anjali', 'from', 'Delhi', 'faced', 'UI', 'issues', 'Rohit', 'from', 'Mumbai', 'gave', 'positive', 'feedback']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stop words ( from , the , etc.)."
      ],
      "metadata": {
        "id": "6wACNdoxdSTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value = {\"from\", \"a\", \"the\", \"had\", \"gave\"}\n",
        "\n",
        "fil_word = word.filter(lambda x: x.lower() not in value)\n",
        "count = fil_word.count()\n",
        "print(\"The number of words are: \", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKtIfX-udU6i",
        "outputId": "e758f7ad-f6f2-47c5-fa51-45db6b2e4555"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words are:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count each word frequency using reduceByKey ."
      ],
      "metadata": {
        "id": "9npsNWXSd0tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = dict(word.map(lambda x: (x.lower(), 1)).reduceByKey(lambda a, b: a + b).collect())\n",
        "print(\"Count of each word:\", word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irXVFFecd3rk",
        "outputId": "7357107c-40f2-4c76-f10b-f9d688d5d467"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of each word: {'from': 5, 'loved': 1, 'liked': 1, 'service': 1, 'anjali': 1, 'faced': 1, 'issues': 1, 'rohit': 1, 'mumbai': 1, 'positive': 1, 'feedback': 1, 'ravi': 1, 'bangalore': 1, 'the': 2, 'delivery': 1, 'meena': 1, 'hyderabad': 1, 'had': 1, 'a': 1, 'late': 1, 'order': 1, 'ajay': 1, 'pune': 1, 'delhi': 1, 'ui': 1, 'gave': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find top 3 most frequent non-stop words."
      ],
      "metadata": {
        "id": "g4fDwVWMelqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "common_words = word.map(lambda x: x.lower()).countByValue()\n",
        "common_words = dict(Counter(common_words).most_common(3))\n",
        "print(\"The top 3 most common words are: \", common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUyVUYzVepIZ",
        "outputId": "c7401256-bfe8-4df1-b32c-cace144d5ba5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 3 most common words are:  {'from': 5, 'the': 2, 'ravi': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 3: DataFrames & Transformation (With Joins)**\n",
        "**DataFrames:**"
      ],
      "metadata": {
        "id": "6kfgwYb2eydi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "students = [\n",
        "(\"Amit\", \"10-A\", 89),\n",
        "(\"Kavya\", \"10-B\", 92),\n",
        "(\"Anjali\", \"10-A\", 78),\n",
        "(\"Rohit\", \"10-B\", 85),\n",
        "(\"Sneha\", \"10-C\", 80)\n",
        "]\n",
        "columns = [\"name\", \"section\", \"marks\"]\n",
        "\n",
        "df_students = spark.createDataFrame(students, columns)\n",
        "\n",
        "df_students.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-rbHHXe4nH",
        "outputId": "7b0e63e5-6d82-4b22-d045-328bfc9c5831"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+\n",
            "|  name|section|marks|\n",
            "+------+-------+-----+\n",
            "|  Amit|   10-A|   89|\n",
            "| Kavya|   10-B|   92|\n",
            "|Anjali|   10-A|   78|\n",
            "| Rohit|   10-B|   85|\n",
            "| Sneha|   10-C|   80|\n",
            "+------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attendance = [\n",
        "(\"Amit\", 24),\n",
        "(\"Kavya\", 22),\n",
        "(\"Anjali\", 20),\n",
        "(\"Rohit\", 25),\n",
        "(\"Sneha\", 19)\n",
        "]\n",
        "columns2 = [\"name\", \"days_present\"]\n",
        "\n",
        "df_attendance = spark.createDataFrame(attendance, columns2)\n",
        "\n",
        "df_attendance.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_FgItDyfbLg",
        "outputId": "ef566356-1f63-4e9b-945e-dc32f7d67a2b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|  name|days_present|\n",
            "+------+------------+\n",
            "|  Amit|          24|\n",
            "| Kavya|          22|\n",
            "|Anjali|          20|\n",
            "| Rohit|          25|\n",
            "| Sneha|          19|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join both DataFrames on name ."
      ],
      "metadata": {
        "id": "qKCWKb3Bff5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "df_joined = df_students.join(df_attendance, \"name\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXOYS_Qxfjbs",
        "outputId": "2d116bb3-5a58-4e54-97cf-3091b15adf20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+\n",
            "|  name|section|marks|days_present|\n",
            "+------+-------+-----+------------+\n",
            "|  Amit|   10-A|   89|          24|\n",
            "|Anjali|   10-A|   78|          20|\n",
            "| Kavya|   10-B|   92|          22|\n",
            "| Rohit|   10-B|   85|          25|\n",
            "| Sneha|   10-C|   80|          19|\n",
            "+------+-------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new column: attendance_rate = days_present / 25 ."
      ],
      "metadata": {
        "id": "ccfB5zrlf34E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_joined.withColumn(\"attendance_rate\", col(\"days_present\") / 25)\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIQ-i7pPf5jm",
        "outputId": "04461dd3-ee20-4e4d-da61-aadd64bc8808"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+\n",
            "|  name|section|marks|days_present|attendance_rate|\n",
            "+------+-------+-----+------------+---------------+\n",
            "|  Amit|   10-A|   89|          24|           0.96|\n",
            "|Anjali|   10-A|   78|          20|            0.8|\n",
            "| Kavya|   10-B|   92|          22|           0.88|\n",
            "| Rohit|   10-B|   85|          25|            1.0|\n",
            "| Sneha|   10-C|   80|          19|           0.76|\n",
            "+------+-------+-----+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grade students using when :\n",
        "A: >90, B: 80–90, C: <80."
      ],
      "metadata": {
        "id": "VdRBoky7gOvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_graded = df_joined.withColumn(\"grade\",\n",
        "    when(col(\"marks\") > 90, \"A\")\n",
        "    .when((col(\"marks\") >= 80) & (col(\"marks\") <= 90), \"B\")\n",
        "    .otherwise(\"C\")\n",
        ")\n",
        "\n",
        "df_graded.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnsJqhobgRX-",
        "outputId": "547fc485-6402-444d-a0fd-d693b462262f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  name|section|marks|days_present|attendance_rate|grade|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  Amit|   10-A|   89|          24|           0.96|    B|\n",
            "|Anjali|   10-A|   78|          20|            0.8|    C|\n",
            "| Kavya|   10-B|   92|          22|           0.88|    A|\n",
            "| Rohit|   10-B|   85|          25|            1.0|    B|\n",
            "| Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter students with good grades but poor attendance (<80%)."
      ],
      "metadata": {
        "id": "_GLd4AISglGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_graded.filter((col(\"grade\").isin(\"A\", \"B\")) & (col(\"attendance_rate\") < 0.8))\n",
        "\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzvR7scygntE",
        "outputId": "b5eb9e01-059b-45a0-c82f-368805e3f309"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| name|section|marks|days_present|attendance_rate|grade|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "|Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 4: Ingest CSV & JSON, Save to Parquet**\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1. Ingest CSV:"
      ],
      "metadata": {
        "id": "mR9QXhiQgsgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"emp_id,name,dept,city,salary\n",
        "101,Anil,IT,Bangalore,80000\n",
        "102,Kiran,HR,Mumbai,65000\n",
        "103,Deepa,Finance,Chennai,72000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"employee.csv\", \"w\") as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "2U2_VAZ9gzDa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ingest JSON:"
      ],
      "metadata": {
        "id": "6w5z1miFhKPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = [\n",
        "{\n",
        "\"id\": 201,\n",
        "\"name\": \"Nandini\",\n",
        "\"contact\": {\n",
        "\"email\": \"nandi@example.com\",\n",
        "\"city\": \"Hyderabad\"\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}\n",
        "]\n",
        "\n",
        "with open(\"employee_nested.json\", \"w\") as f:\n",
        "    f.write(str(json_data))"
      ],
      "metadata": {
        "id": "FHQrPVJ_hM2P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "Read both formats into DataFrames."
      ],
      "metadata": {
        "id": "PPJyCIkOhswq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = spark.read.option(\"header\", True).csv(\"employee.csv\")\n",
        "df_csv.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZA8SUFThz45",
        "outputId": "96884288-e524-4acd-d6fd-5fefc29187f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+---------+------+\n",
            "|emp_id| name|   dept|     city|salary|\n",
            "+------+-----+-------+---------+------+\n",
            "|   101| Anil|     IT|Bangalore| 80000|\n",
            "|   102|Kiran|     HR|   Mumbai| 65000|\n",
            "|   103|Deepa|Finance|  Chennai| 72000|\n",
            "+------+-----+-------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_json = spark.read.json(\"employee_nested.json\")\n",
        "df_json.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qYzTJz8iWsE",
        "outputId": "77ad5726-fd3e-436c-d037-220f7109818f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---+-------+--------------------+\n",
            "|             contact| id|   name|              skills|\n",
            "+--------------------+---+-------+--------------------+\n",
            "|{Hyderabad, nandi...|201|Nandini|[Python, Spark, SQL]|\n",
            "+--------------------+---+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten nested JSON using select , col , alias , explode ."
      ],
      "metadata": {
        "id": "dScDZPgXirb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "df_flat = df_json.select(\n",
        "    col(\"id\"),\n",
        "    col(\"name\"),\n",
        "    col(\"contact.city\").alias(\"city\"),\n",
        "    explode(col(\"skills\")).alias(\"skill\")\n",
        ")\n",
        "\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpYjbG4pinb7",
        "outputId": "3849e056-ee6f-45a6-efbf-66cc40fee7fc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------+------+\n",
            "| id|   name|     city| skill|\n",
            "+---+-------+---------+------+\n",
            "|201|Nandini|Hyderabad|Python|\n",
            "|201|Nandini|Hyderabad| Spark|\n",
            "|201|Nandini|Hyderabad|   SQL|\n",
            "+---+-------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save both as Parquet files partitioned by city."
      ],
      "metadata": {
        "id": "3D87IcY4l4PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"output/csv_parquet\")\n",
        "df_flat.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"output/json_parquet\")"
      ],
      "metadata": {
        "id": "Q0yIPz62l6xl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 5: Spark SQL with Temp Views**\n",
        "**Tasks:**\n",
        "\n",
        "Register the students DataFrame as students_view ."
      ],
      "metadata": {
        "id": "JWT2-bTUnNiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_graded.createOrReplaceTempView(\"students_view\")"
      ],
      "metadata": {
        "id": "LYcIeNBXoFbN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write and run the following queries:\n",
        "\n",
        "a) Average marks per section"
      ],
      "metadata": {
        "id": "ljk49xWWofgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT section, AVG(marks) as avg_marks FROM students_view GROUP BY section\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gafk3ul2oXAW",
        "outputId": "e72ea958-f653-40e3-bbce-1bee58c6745c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|section|avg_marks|\n",
            "+-------+---------+\n",
            "|   10-C|     80.0|\n",
            "|   10-A|     83.5|\n",
            "|   10-B|     88.5|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Top scorer in each section"
      ],
      "metadata": {
        "id": "Jr7SUzE9oolL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT section, name, marks FROM (SELECT *, RANK() OVER (PARTITION BY section ORDER BY marks DESC) as rnk FROM students_view ) WHERE rnk = 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9dCM2GqoqwI",
        "outputId": "7ffac482-e291-4048-ea3c-cb3724b1c401"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|section| name|marks|\n",
            "+-------+-----+-----+\n",
            "|   10-A| Amit|   89|\n",
            "|   10-B|Kavya|   92|\n",
            "|   10-C|Sneha|   80|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Count of students in each grade category"
      ],
      "metadata": {
        "id": "mP9EtTTbo2MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT grade, COUNT(*) as count FROM students_view GROUP BY grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPUBYMdKo5pJ",
        "outputId": "476ac292-7e87-4d41-e123-1bd282b51970"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|grade|count|\n",
            "+-----+-----+\n",
            "|    B|    3|\n",
            "|    C|    1|\n",
            "|    A|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Students with marks above class average"
      ],
      "metadata": {
        "id": "BpHUO60upEYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT name, marks FROM students_view WHERE marks > (SELECT AVG(marks) FROM students_view)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhCZpa04pIGX",
        "outputId": "bcfd81bd-c88d-4c97-fce9-58718a52f26c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "| name|marks|\n",
            "+-----+-----+\n",
            "| Amit|   89|\n",
            "|Kavya|   92|\n",
            "|Rohit|   85|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Attendance-adjusted performance"
      ],
      "metadata": {
        "id": "bWTW3TMSpNe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT name, section, marks, attendance_rate, marks * attendance_rate as adjusted_score FROM students_view\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RZLWFzxpR_1",
        "outputId": "bfd71f37-64ec-45bb-c84c-2e134669b254"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+---------------+------------------+\n",
            "|  name|section|marks|attendance_rate|    adjusted_score|\n",
            "+------+-------+-----+---------------+------------------+\n",
            "|  Amit|   10-A|   89|           0.96|             85.44|\n",
            "|Anjali|   10-A|   78|            0.8|62.400000000000006|\n",
            "| Kavya|   10-B|   92|           0.88|             80.96|\n",
            "| Rohit|   10-B|   85|            1.0|              85.0|\n",
            "| Sneha|   10-C|   80|           0.76|              60.8|\n",
            "+------+-------+-----+---------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 6: Partitioned Data & Incremental Loading**\n",
        "**Step 1: Full Load**"
      ],
      "metadata": {
        "id": "n1sUthwZpg-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.write.mode(\"overwrite\").partitionBy(\"section\").parquet(\"output/students\")"
      ],
      "metadata": {
        "id": "r9R8aYD2pmRs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Incremental Load**"
      ],
      "metadata": {
        "id": "O5HP6VX4qKYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Tejas\", \"10-A\", 91)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\", \"section\", \"marks\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "dyvRs7onqN6o"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "List files in output/students/ using Python."
      ],
      "metadata": {
        "id": "xYPQsBEyqRbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"output/students\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfzl_evxqWEf",
        "outputId": "d9109403-3d47-4224-b284-2f082888ad2b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['._SUCCESS.crc', 'section=10-A', 'section=10-B', '_SUCCESS', 'section=10-C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read only partition 10-A and list students."
      ],
      "metadata": {
        "id": "ALOyNHe0qaEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_10a = spark.read.parquet(\"output/students/section=10-A\")\n",
        "df_10a.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKS-6KCVqcuU",
        "outputId": "1964f74a-4ca6-475c-e681-d82b2ca525a7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|  name|marks|\n",
            "+------+-----+\n",
            "|Anjali|   78|\n",
            "| Tejas|   91|\n",
            "|  Amit|   89|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare before/after counts for section 10-A ."
      ],
      "metadata": {
        "id": "6kT-QsokqhCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Count: {df_10a.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZJfWAlRqjTj",
        "outputId": "8022c5e4-d129-4013-99aa-90e822b0d83d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 7: ETL Pipeline – End to End**\n",
        "**Given Raw Data (CSV):**"
      ],
      "metadata": {
        "id": "qnSmZbnLqmkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = \"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,75000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,68000,4000\n",
        "4,Ramesh,Sales,58000\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Y1BufQDcqtJE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "Load CSV with inferred schema."
      ],
      "metadata": {
        "id": "OjX9e5B3q8ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"employee_raw.csv\", \"w\") as f:\n",
        "    f.write(datas)\n",
        "\n",
        "df_raw = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"employee_raw.csv\")\n",
        "\n",
        "df_raw.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2MJrBXxq7tv",
        "outputId": "c63f152a-41a9-4467-97a0-5771b4fae7ed"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| NULL|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| NULL|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill null bonuses with 2000 ."
      ],
      "metadata": {
        "id": "sd-PW_KerZEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_raw.fillna({\"bonus\": 2000})\n",
        "df_clean.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkAXRj6JrX-c",
        "outputId": "21933e8e-c86d-43e5-e07e-c4f8c6961293"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| 2000|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create total_ctc = salary + bonus ."
      ],
      "metadata": {
        "id": "oxoY15IKrhX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_clean.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))\n",
        "df_clean.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da1N_gv1rj_2",
        "outputId": "1899e13c-6ee2-46d5-804f-c8eb01f44c7d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+---------+\n",
            "|emp_id|  name|   dept|salary|bonus|total_ctc|\n",
            "+------+------+-------+------+-----+---------+\n",
            "|     1| Arjun|     IT| 75000| 5000|    80000|\n",
            "|     2| Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3| Sneha|Finance| 68000| 4000|    72000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|    60000|\n",
            "+------+------+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter employees with total_ctc > 65000 ."
      ],
      "metadata": {
        "id": "361He1uLrq41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df_clean.filter(col(\"total_ctc\") > 65000)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02CUHTG4rtbA",
        "outputId": "ec5566b8-91e8-477b-cbc4-2057f3e0993f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 75000| 5000|    80000|\n",
            "|     3|Sneha|Finance| 68000| 4000|    72000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save result in: JSON format."
      ],
      "metadata": {
        "id": "2H5E56lorzZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.write.mode(\"overwrite\").json(\"output/high_ctc_json\")"
      ],
      "metadata": {
        "id": "MZ9wIZ7Kr5DV"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parquet format partitioned by department."
      ],
      "metadata": {
        "id": "zCujf9vAr873"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.write.mode(\"overwrite\").partitionBy(\"dept\").parquet(\"output/high_ctc_parquet\")"
      ],
      "metadata": {
        "id": "10I9CaJfsANd"
      },
      "execution_count": 69,
      "outputs": []
    }
  ]
}